{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://ai.meng.duke.edu'> = <img align=\"left\" style=\"padding-top:10px;\" src='OCR_logo3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting sensors for a stress detection wearable device\n",
    "\n",
    "_Version 1.0_  \n",
    "_Author(s): Jon Reifschneider, Duke University Pratt School of Engineering_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" style=\"padding-top:10px;\" src=\"Respiban.png\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _About this teaching case_\n",
    "**Level:** Beginner  \n",
    "**Language:** Python  \n",
    "**Libraries:** Pandas, Matplotlib  \n",
    "**Industry:** Healthcare\n",
    "\n",
    "**Learning Topics:**  \n",
    "- Data Manipulation\n",
    "- Exploratory Data Analysis\n",
    "- Outliers  \n",
    "\n",
    "**Learning Objectives**   \n",
    "- Learn to read in, clean and filter raw sensor data\n",
    "- Learn strategies for identifying and removing outliers in data\n",
    "- Build skills in exploratory data analysis using visual and statistical analysis techniques\n",
    "\n",
    "**Pre-requisites**  \n",
    "- Basic proficiency in Python and pandas\n",
    "\n",
    "**Case Structure**  \n",
    "This teaching case is structured to follow the ***Modified CRISP-DM Data Science Process*** used in Duke University's AI for Product Innovation graduate programs. \n",
    "\n",
    "**Datasets Used**  \n",
    "Philip Schmidt, Attila Reiss, Robert Duerichen, Claus Marberger and Kristof Van Laerhoven. 2018. Introducing WESAD, a multimodal dataset for Wearable Stress and Affect Detection. In 2018 International Conference on Multimodal Interaction (ICMI ’18), October 16–20, 2018, Boulder, CO, USA. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3242969.3242985\n",
    "\n",
    "Originial (unadjusted) dataset can be found at https://ubicomp.eti.uni-siegen.de/home/datasets/icmi18/. The dataset used in this exercise has been adapted from the original to facilitate the learning objectives of this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "[1: Business Understanding](#1)  \n",
    "[2: Data Understanding](#2)  \n",
    "&nbsp;&nbsp;[2.1: Gather Data](#3)  \n",
    "&nbsp;&nbsp;[2.2: Validate Data](#4)   \n",
    "&nbsp;&nbsp;[2.3: Explore Data](#5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this before any other code cell\n",
    "# This downloads the csv data files into the same directory where you have saved this notebook\n",
    "\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import os\n",
    "path = Path()\n",
    "\n",
    "# Dictionary of file names and download links\n",
    "files = {'S2_respiban_adjusted.txt':'https://storage.googleapis.com/aipi_datasets/S2_respiban_adjusted.txt'}\n",
    "\n",
    "# Download each file\n",
    "for key,value in files.items():\n",
    "    filename = path/key\n",
    "    url = value\n",
    "    # If the file does not already exist in the directory, download it\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Business Understanding <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "## 1.1 Define the problem\n",
    "Long-term stress has been proven to have harmful health effects, ranging from headaches, sleeping difficulties, and even increased risk for cardiovascular diseases.  The ability for individuals to automatically detect signs of ongoing stress can help them to seek intervention to reduce stress levels, resulting in a reduction in harmful side-effects. \n",
    "\n",
    "You are an engineer working for a company developing a wearable chest-strap stress detection device which uses sensors to detect physiological signs of stress and then alerts the user so they can take proactive action to reduce stress, in order to mitigate potential long-term health effects.  You have been asked to lead a project to determine which sensors need to be included on the new wearable device in order to accurately detect stress.\n",
    "\n",
    "## 1.2 Define success\n",
    "The expected impact of the company's product will be to enable early mitigation of ongoing stress for users, resulting in a reduction in negative health impacts due to stress, e.g. headaches. In order to achieve this, the company need to be able to accurately identify periods of stress as compared to non-stress periods. \n",
    "\n",
    "## 1.3 Identify factors\n",
    "\n",
    "From your interviews of domain experts, you learn that stress is a physiological response to stimulus triggered by the sympathetic nervous system.  During this response, hormones are released that lead to physiological changes such as increased respiratory rate, increased heart rate, muscle tension, and increased motion.  In order to determine which sensors may be needed to provide input into the model to predict stress, you have developed a list of physiological and motion signals which can be feasibly measured by sensors on a non-invasive wearable device:  \n",
    "- Motion/acceleration\n",
    "- Electrocardiography\n",
    "- Electrodermal activity\n",
    "- Electromyography\n",
    "- Respiration\n",
    "- Skin temperature\n",
    "\n",
    "Your plan is to evaluate each of these signals to identify which ones contain patterns that may provide an indicator of stress.  This will help you narrow down the list of sensors needed on the wearable device to only those which have value for collecting data to drive a stress identification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Understanding <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "You have gathered data you plan to use for an initial analysis from the Wearable Stress and Affect Detection (WESAD) study done by engineers at Bosch which includes high-resolution data from several sensors together with labels of the subject's mood at each point in time over the duration of the study period.  The sensors are contained on two devices - one chest-based and the other wrist-based.  The description of the data in the study is below.  The study contains data on several participants - for the initial analysis you will use the data for just one individual (S2) from the RespiBAN chest sensor array.\n",
    "\n",
    "**Description of the dataset:**  \n",
    "The study authors used the RespiBAN chest sensor to measure physiological signals and motion: http://www.biosignalsplux.com/en/respiban-professional. All signals were sampled at 700 Hz. Raw data is contained in SX_respiban.txt. There are 10 columns here. First column: sequential line number. Second column: ignore. Columns 3-10: raw data of the 8 sensor channels. The order of the channels is defined in the header. The entries “XYZ” refer to the 3-channel accelerometer (thus, acceleration data is provided in 3 columns). In order to convert the raw sensor values into SI units, each channel has to transformed based on the formulas given below (signal contains the raw sensor values, vcc=3, chan_bit=2^16).\n",
    "- ECG (mV): ((signal/chan_bit-0.5)*vcc) Details: http://www.biosignalsplux.com/datasheets/ECG_Sensor_Datasheet.pdf\n",
    "- EDA (μS): (((signal/chan_bit)*vcc)/0.12) Details: http://www.biosignalsplux.com/datasheets/EDA_Sensor_Datasheet.pdf\n",
    "- EMG (mV): ((signal/chan_bit-0.5)*vcc) Details: http://www.biosignalsplux.com/datasheets/EMG_Sensor_Datasheet.pdf\n",
    "- TEMP (°C):  \n",
    "    vout = (signal*vcc)/(chan_bit)  \n",
    "    rntc = ((10^4)*vout)/(vcc-vout)  \n",
    "    TEMP = - 273.15 + 1./(1.12764514*10^(-3) + 2.34282709*10^(-4)*log(rntc) + 8.77303013*10^(-8)*(log(rntc))^3)  \n",
    "    Details: http://www.biosignalsplux.com/datasheets/TMP_Sensor_Datasheet.pdf\n",
    "- XYZ (g): (signal-Cmin)/(Cmax-Cmin)*2-1, where Cmin = 28000 and Cmax = 38000  \n",
    "Details: http://www.biosignalsplux.com/datasheets/ACC_Sensor_Datasheet.pdf\n",
    "- RESPIRATION (%): (signal / chan_bit - 0.5) * 100 Details: http://www.biosignalsplux.com/datasheets/PZT_Sensor_Datasheet.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Gather data <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run setup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Read in the raw data from the txt file\n",
    "raw_data = pd.read_csv('S2_respiban_adjusted.txt',sep = '\\t',skiprows=3,header=None,)\n",
    "chest_data = raw_data.copy() # Work with a copy to preserve the raw dataframe\n",
    "\n",
    "# Read in the metadata\n",
    "with open('S2_respiban_adjusted.txt') as f:\n",
    "    lines = f.readlines()\n",
    "metadata = lines[1]\n",
    "\n",
    "# Read in the labels csv to a dictionary containing label and start and end time for each\n",
    "labels = {}\n",
    "with open('S2_labels.csv') as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines[1:]:\n",
    "    key = line.split(';')[0].strip('# ')\n",
    "    values = [line.strip() for line in line.split(';')[1:]]\n",
    "    labels[key] = values\n",
    "# Convert start and end times to float\n",
    "labels['START'] = [float(x) for x in labels['START']]\n",
    "labels['END'] = [float(x) for x in labels['END']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-998795e8087fe51b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use Python string operations to extract the column names (signals) from the metadata and put them into a list called *colnames*. The column names are contained in a list with the key \"sensor\" in the metadata dictionary.  They should be stored in the list as strings with no additional punctuation or white space around them. E .g. ['ECG', 'EDA', ...]\n",
    "\n",
    "Delete columns 0,1,10 from the *chest_data* dataframe per the data description.  Then, rename the columns to the column names you just extracted from the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c47a7b44b5ab0d59",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "# Check to confirm correct values in colnames\n",
    "assert colnames == ['ECG', 'EDA', 'EMG', 'TEMP', 'XYZ1', 'XYZ2', 'XYZ3', 'RESPIRATION'], 'colnames is incorrect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad6ed63faa5b129f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's add a time attribute to our data.  The chest sensor and label data is sampled at 700 Hz  \n",
    "\n",
    "Convert the dataframe index to a timedelta index with the values in seconds.  The chest sensor and label data is sampled at 700 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-76908ef6fed4bc67",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "# Check that total time is correct\n",
    "assert round(np.max(chest_data.index.total_seconds())/60,ndigits=0) == 106"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth mood labels for the data are contained in S2_labels.csv, which has been read in to a dictionary *labels* containing label and start and end time for each.  Add a 'label' column to your dataframe containing the corresponding string label for each row, based on start/end time of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "    \n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Validate data  <a class=\"anchor\" id=\"4\"></a>\n",
    "### Transform raw sensor data into proper units  \n",
    "Use the transfer function equations given in the sensor spec sheets (and the description above in the Data Understanding section) to convert the raw values into the proper units.  Write a function *unitize(df,vcc,chan_bit,Cmax,Cmin)* to convert the raw data values from ALL sensors in the input dataframe to proper units.  As an example, the calculation for temperature conversion is provided.  The inputs are the raw data dataframe *df* and variables *vcc*, *chan_bit*, *Cmax* and *Cmin*.  The function returns a dataframe *df_units* with the same columns as the original input dataframe, converted into proper units.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5613497ff5642e8f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def unitize(df, vcc, chan_bit, Cmax, Cmin):\n",
    "    df_units = df.copy()\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "  \n",
    "   \n",
    "    ## END SOLUTION\n",
    "    \n",
    "    return df_units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your new function to convert chest_data into proper units.  Let's also combine our three components of acceleration to get one acceleration factor with the total magnitude of acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up missing and erroneous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if we have missing data in any of our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if we have missing data in any of our columns\n",
    "chest_data_units.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7dbd320711428e04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As we can see above, we have several rows of data with null values for sensor readings.  What might be some possible reasons why we have missing data in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-40e9f7873464cdc8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are dealing with a time series, rather than simply discarding the missing values an alternative approach would be to use a backwards or forward fill to fill them in using the values from the previous or the next observation from the sensors.  \n",
    "\n",
    "Define a function clean_data() which takes as input a dataframe containing data to clean (*chest_data_units*) and a list of labels to filter on (*relevant_labels*).  The function should first filter the dataframe to only contain rows with a label included in *relevant_labels*.  It should then fill the null signal values in the filtered dataframe using a forward-fill approach (set them equal to the last observed value in time before the null value).  The function should return the cleaned and filtered dataframe as *df_clean*.  Once we have filtered and filled null signal values, we should have no null values left in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5499a9e7256c641b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "relevant_labels=['Baseline','Stressed','Amusement']\n",
    "\n",
    "def clean_data(df, relevant_labels):\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chest_data_clean = clean_data(chest_data_units,relevant_labels)\n",
    "\n",
    "# Check to see if all null values have been filled\n",
    "assert chest_data_clean.isna().sum(axis=0).sum()==0, 'The dataframe still contains null values!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for anomalous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visual check for outliers**  \n",
    "A good place to start in looking for anomalous values is by visually evaluating the data. Let's do this by creating a simple plot of each signal over the period, and observe whether we see unusual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots, it looks like there may be a few severe outliers in the data.  Select an appropriate approach to identifying extreme outliers in the data, and then remove the extreme outliers from your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-efb9cf65f61ee0af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.3 Explore the data <a class=\"anchor\" id=\"5\"></a>\n",
    "\n",
    "Our data is now in proper units, filtered for modeling, and scrubbed to remove null values and anomalies.  Now we are ready to explore the data to identify trends and patterns which we can use to determine which sensors help us most in identifying periods of stress.\n",
    "\n",
    "For each signal, visually analyze the signal values for each mood label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-080928735d09daca",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-74b4df12b4d1e2ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, compute and compare the mean and standard deviation values of each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-63394d26db951594",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e3b2c6585dfbfc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For the signals which appear to have a large difference in the mean of \"stressed\" (label==2) relative to the other two mood states, use an ANOVA to determine if the difference between the mean signal values for the groups is statistically significant at a level of 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9b13b7889f74bf6d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "    \n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6e61283b0d32dc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, for any signals that you suspect provide a good indicator of stress, it is a good idea to plot the data again, this time identifying the set of values corresponding to each mood using a different color so that we can visually compare the trend in values for each mood.  Why do we do this? Because sometimes there are other indicators we might look for in the data beyond a difference in means between groups (e.g. one group might have a much higher variance than the others, or there might be an increasing/decreasing trend in values of one group not seen in the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-525dd51a4dfaaae4",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "\n",
    "## END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0fbb4f50708645e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Based on the visual and statistical analyses you ran above, which sensors do you recommend including on our wearable stress detector device? Why? Please justify your answer by referring to the data and plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1eebe6c3c94c3bae",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
